{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-pNREKOX_6mm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaikesh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66802"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[]\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "import numpy as np\n",
    "# In[]\n",
    "\n",
    "\n",
    "import string\n",
    "import re\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "\n",
    "\n",
    "    tokens = [re.sub(r'[^\\w\\s]','',w) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# In[]\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "tokens_raw1 = gutenberg.words('austen-emma.txt')\n",
    "n1 = len(tokens_raw1)\n",
    "tokens_train1  = tokens_raw1[0:int(0.8*n1)];\n",
    "tokens_test1 = tokens_raw1[int(0.8*n1):n1]; \n",
    "\n",
    "tokens_raw2 = gutenberg.words('austen-sense.txt')\n",
    "n2 = len(tokens_raw2)\n",
    "tokens_train2  = tokens_raw2[0:int(0.8*n2)];\n",
    "tokens_test2 = tokens_raw2[int(0.8*n2):n2]; \n",
    "\n",
    "tokens_raw = tokens_train1 + tokens_train2\n",
    "tokens_test = tokens_test1 + tokens_test2\n",
    "\n",
    "text_raw = ' '.join(tokens_raw)\n",
    "tokens = clean_doc(text_raw)\n",
    "\n",
    "\n",
    "\n",
    "len(tokens_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LB5gs9hLM3ru"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 112954\n"
     ]
    }
   ],
   "source": [
    "# In[]\n",
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "step =2\n",
    "sequences = list()\n",
    "for i in range(0,len(tokens)-length, step):\n",
    "\t# select sequence of tokens\n",
    "\tseq = tokens[i:i+length]\n",
    "\t# convert into a line\n",
    "\tline = ' '.join(seq)\n",
    "\t# store\n",
    "\tsequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZQMb-7F1MuE0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sequences\n",
    "# In[]\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "\n",
    "# In[]\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# In[]\n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I0GkyqlTMerN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 500)           4139000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           240400    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8278)              836078    \n",
      "=================================================================\n",
      "Total params: 5,305,978\n",
      "Trainable params: 5,305,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 500, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I0GkyqlTMerN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "112954/112954 [==============================] - 401s 4ms/step - loss: 6.3789 - acc: 0.0387\n",
      "Epoch 2/80\n",
      "112954/112954 [==============================] - 428s 4ms/step - loss: 5.9430 - acc: 0.0642\n",
      "Epoch 3/80\n",
      "112954/112954 [==============================] - 439s 4ms/step - loss: 5.7418 - acc: 0.0800\n",
      "Epoch 4/80\n",
      "112954/112954 [==============================] - 438s 4ms/step - loss: 5.5589 - acc: 0.0961\n",
      "Epoch 5/80\n",
      "112954/112954 [==============================] - 439s 4ms/step - loss: 5.3702 - acc: 0.1100\n",
      "Epoch 6/80\n",
      "112954/112954 [==============================] - 435s 4ms/step - loss: 5.2284 - acc: 0.1214\n",
      "Epoch 7/80\n",
      "112954/112954 [==============================] - 450s 4ms/step - loss: 5.1126 - acc: 0.1301\n",
      "Epoch 8/80\n",
      "112954/112954 [==============================] - 454s 4ms/step - loss: 5.0072 - acc: 0.1383\n",
      "Epoch 9/80\n",
      "112954/112954 [==============================] - 450s 4ms/step - loss: 4.9113 - acc: 0.1443\n",
      "Epoch 10/80\n",
      "112954/112954 [==============================] - 445s 4ms/step - loss: 4.8188 - acc: 0.1508\n",
      "Epoch 11/80\n",
      "112954/112954 [==============================] - 464s 4ms/step - loss: 4.7308 - acc: 0.1565\n",
      "Epoch 12/80\n",
      "112954/112954 [==============================] - 459s 4ms/step - loss: 4.6471 - acc: 0.1616\n",
      "Epoch 13/80\n",
      "112954/112954 [==============================] - 427s 4ms/step - loss: 4.5690 - acc: 0.1675\n",
      "Epoch 14/80\n",
      "112954/112954 [==============================] - 431s 4ms/step - loss: 4.4948 - acc: 0.1720\n",
      "Epoch 15/80\n",
      "112954/112954 [==============================] - 443s 4ms/step - loss: 4.4256 - acc: 0.1771\n",
      "Epoch 16/80\n",
      "112954/112954 [==============================] - 457s 4ms/step - loss: 4.3605 - acc: 0.1819\n",
      "Epoch 17/80\n",
      "112954/112954 [==============================] - 445s 4ms/step - loss: 4.2985 - acc: 0.1858\n",
      "Epoch 18/80\n",
      "112954/112954 [==============================] - 438s 4ms/step - loss: 4.2392 - acc: 0.1903\n",
      "Epoch 19/80\n",
      "112954/112954 [==============================] - 456s 4ms/step - loss: 4.1821 - acc: 0.1954\n",
      "Epoch 20/80\n",
      "112954/112954 [==============================] - 447s 4ms/step - loss: 4.1278 - acc: 0.2001\n",
      "Epoch 21/80\n",
      "112954/112954 [==============================] - 453s 4ms/step - loss: 4.0758 - acc: 0.2052\n",
      "Epoch 22/80\n",
      "112954/112954 [==============================] - 451s 4ms/step - loss: 4.0270 - acc: 0.2097\n",
      "Epoch 23/80\n",
      "112954/112954 [==============================] - 456s 4ms/step - loss: 3.9797 - acc: 0.2143\n",
      "Epoch 24/80\n",
      "112954/112954 [==============================] - 457s 4ms/step - loss: 3.9318 - acc: 0.2196\n",
      "Epoch 25/80\n",
      "112954/112954 [==============================] - 410s 4ms/step - loss: 3.8884 - acc: 0.2249\n",
      "Epoch 26/80\n",
      "112954/112954 [==============================] - 411s 4ms/step - loss: 3.8420 - acc: 0.2300\n",
      "Epoch 27/80\n",
      "112954/112954 [==============================] - 414s 4ms/step - loss: 3.8017 - acc: 0.2353\n",
      "Epoch 28/80\n",
      "112954/112954 [==============================] - 414s 4ms/step - loss: 3.7605 - acc: 0.2407\n",
      "Epoch 29/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.7199 - acc: 0.2459\n",
      "Epoch 30/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.6804 - acc: 0.2509\n",
      "Epoch 31/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.6423 - acc: 0.2559\n",
      "Epoch 32/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.6050 - acc: 0.2611\n",
      "Epoch 33/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.5662 - acc: 0.2659\n",
      "Epoch 34/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.5304 - acc: 0.2706\n",
      "Epoch 35/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.4952 - acc: 0.2758\n",
      "Epoch 36/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.4584 - acc: 0.2816\n",
      "Epoch 37/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.4246 - acc: 0.2873\n",
      "Epoch 38/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.3874 - acc: 0.2933\n",
      "Epoch 39/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.3545 - acc: 0.2974\n",
      "Epoch 40/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.3186 - acc: 0.3033\n",
      "Epoch 41/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.2872 - acc: 0.3077\n",
      "Epoch 42/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.2525 - acc: 0.3138\n",
      "Epoch 43/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.2248 - acc: 0.3176\n",
      "Epoch 44/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.1932 - acc: 0.3218\n",
      "Epoch 45/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 3.1580 - acc: 0.3289\n",
      "Epoch 46/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 3.1253 - acc: 0.3337\n",
      "Epoch 47/80\n",
      "112954/112954 [==============================] - 421s 4ms/step - loss: 3.0967 - acc: 0.3371\n",
      "Epoch 48/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 3.0656 - acc: 0.3422\n",
      "Epoch 49/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 3.0348 - acc: 0.3475\n",
      "Epoch 50/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 3.0062 - acc: 0.3533\n",
      "Epoch 51/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 2.9765 - acc: 0.3592\n",
      "Epoch 52/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 2.9479 - acc: 0.3631\n",
      "Epoch 53/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.9206 - acc: 0.3667\n",
      "Epoch 54/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.8924 - acc: 0.3730\n",
      "Epoch 55/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.8697 - acc: 0.3766\n",
      "Epoch 56/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.8360 - acc: 0.3807\n",
      "Epoch 57/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.8093 - acc: 0.3861\n",
      "Epoch 58/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 2.7831 - acc: 0.3907\n",
      "Epoch 59/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.7579 - acc: 0.3959\n",
      "Epoch 60/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 2.7329 - acc: 0.3993\n",
      "Epoch 61/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.7082 - acc: 0.4044\n",
      "Epoch 62/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.6842 - acc: 0.4084\n",
      "Epoch 63/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.6550 - acc: 0.4136\n",
      "Epoch 64/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.6333 - acc: 0.4181\n",
      "Epoch 65/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.6186 - acc: 0.4194\n",
      "Epoch 66/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.5860 - acc: 0.4249\n",
      "Epoch 67/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.5610 - acc: 0.4296\n",
      "Epoch 68/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.5433 - acc: 0.4338\n",
      "Epoch 69/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.5152 - acc: 0.4383\n",
      "Epoch 70/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.5032 - acc: 0.4408\n",
      "Epoch 71/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.4767 - acc: 0.4446\n",
      "Epoch 72/80\n",
      "112954/112954 [==============================] - 416s 4ms/step - loss: 2.4557 - acc: 0.4494\n",
      "Epoch 73/80\n",
      "112954/112954 [==============================] - 419s 4ms/step - loss: 2.4315 - acc: 0.4537\n",
      "Epoch 74/80\n",
      "112954/112954 [==============================] - 417s 4ms/step - loss: 2.4134 - acc: 0.4582\n",
      "Epoch 75/80\n",
      "112954/112954 [==============================] - 417s 4ms/step - loss: 2.3927 - acc: 0.4618\n",
      "Epoch 76/80\n",
      "112954/112954 [==============================] - 417s 4ms/step - loss: 2.3695 - acc: 0.4665\n",
      "Epoch 77/80\n",
      "112954/112954 [==============================] - 417s 4ms/step - loss: 2.3547 - acc: 0.4668\n",
      "Epoch 78/80\n",
      "112954/112954 [==============================] - 417s 4ms/step - loss: 2.3310 - acc: 0.4713\n",
      "Epoch 79/80\n",
      "112954/112954 [==============================] - 415s 4ms/step - loss: 2.3175 - acc: 0.4748\n",
      "Epoch 80/80\n",
      "112954/112954 [==============================] - 414s 4ms/step - loss: 2.2934 - acc: 0.4790\n"
     ]
    }
   ],
   "source": [
    "# In[]\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=80)\n",
    "\n",
    "# In[]\n",
    "\n",
    "# save the model to file\n",
    "model.save('model_a03_wl_500_100_80.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer_a03_wl_500_100_80.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "# load the model\n",
    "model = load_model('model_a03_wl_500_100_80.h5')\n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer_a03_wl_500_100_80.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I0GkyqlTMerN"
   },
   "outputs": [],
   "source": [
    "# In[]\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "\tresult = list()\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# truncate sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "        #yhat1 = model.predict(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\t\tresult.append(out_word)\n",
    "\treturn ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Yy1OBGbKAIaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mourning in secret over obstacles which must divide her for ever from the object of her love and that marianne was internally dwelling on the perfections of a man of whose whole heart she felt thoroughly possessed and whom she expected to see in every carriage which drove near their house\n",
      "\n",
      "and of temptation her own imagination and impetuous him that she knew her impatience to\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 15)\n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LOibiu6EJJV0"
   },
   "outputs": [],
   "source": [
    "#perplexity\n",
    "\n",
    "test_tokens = tokens_test[1:10000]\n",
    "\n",
    "in_text = test_tokens[0]\n",
    "logp = 0\n",
    "c=0\n",
    "for word in test_tokens:\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "    yhat1 = model.predict(encoded,verbose=0)[0]\n",
    "    next_word = word\n",
    "    if next_word in tokenizer.word_index:\n",
    "        p = yhat1[tokenizer.word_index[next_word]]\n",
    "        if  p >=0.00001:\n",
    "            c+=1\n",
    "            logp = logp + np.log(p)\n",
    "\n",
    "    else:\n",
    "        p = 1\n",
    "        c+=1\n",
    "        logp = logp + np.log(p)\n",
    "    \n",
    "    in_text +=' ' + next_word\n",
    "pplxty = np.exp(-1*logp/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u1kS54TaJXCx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.732750104716793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print c\n",
    "pplxty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aV8_uO8hJ7Jo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "a03_wl_300_100_80_singlelayer.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
